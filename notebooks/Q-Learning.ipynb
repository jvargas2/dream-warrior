{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "=============\n",
      "EPISODE 0\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 1.000000\n",
      "Random Sample: 0.304945\n",
      "EXPLORATION\n",
      "Action Selected: Up\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-1.00 + 0.99(0.00))\n",
      "0.00 + 0.70(-1.00)\n",
      "-0.70\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "|L|B| |\n",
      "| | |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [0.00, 0.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [0.00, 0.00, -0.70, 0.00]\n",
      "6: [0.00, 0.00, 0.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 1.000000\n",
      "Random Sample: 0.355608\n",
      "EXPLORATION\n",
      "Action Selected: Left\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-1.00 + 0.99(0.00))\n",
      "0.00 + 0.70(-1.00)\n",
      "-0.70\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "|L|B| |\n",
      "| | |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, 0.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [0.00, 0.00, -0.70, 0.00]\n",
      "6: [0.00, 0.00, 0.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 1.000000\n",
      "Random Sample: 0.940343\n",
      "EXPLORATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-10.00 + 0.99(0.00))\n",
      "0.00 + 0.70(-10.00)\n",
      "-7.00\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |L| |\n",
      "| | |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [0.00, 0.00, -0.70, 0.00]\n",
      "6: [0.00, 0.00, 0.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 1\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.900000\n",
      "Random Sample: 0.715384\n",
      "EXPLORATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-1.00 + 0.99(0.00))\n",
      "0.00 + 0.70(-1.00)\n",
      "-0.70\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [0.00, -0.70, -0.70, 0.00]\n",
      "6: [0.00, 0.00, 0.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.900000\n",
      "Random Sample: 0.366836\n",
      "EXPLORATION\n",
      "Action Selected: Up\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-10.00 + 0.99(0.00))\n",
      "0.00 + 0.70(-10.00)\n",
      "-7.00\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |L| |\n",
      "| | |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [0.00, -0.70, -0.70, 0.00]\n",
      "6: [0.00, 0.00, -7.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 2\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.800000\n",
      "Random Sample: 0.887821\n",
      "EXPLOITATION\n",
      "Action Selected: Left\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-1.00 + 0.99(0.00))\n",
      "0.00 + 0.70(-1.00)\n",
      "-0.70\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-0.70, -0.70, -0.70, 0.00]\n",
      "6: [0.00, 0.00, -7.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.800000\n",
      "Random Sample: 0.868281\n",
      "EXPLOITATION\n",
      "Action Selected: Down\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-1.00 + 0.99(0.00))\n",
      "0.00 + 0.70(-1.00)\n",
      "-0.70\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-0.70, -0.70, -0.70, -0.70]\n",
      "6: [0.00, 0.00, -7.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.800000\n",
      "Random Sample: 0.453406\n",
      "EXPLORATION\n",
      "Action Selected: Left\n",
      "Old Q-Value: -0.70\n",
      "Next Q-Value: -0.70\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-0.70) + 0.70(-1.00 + 0.99(-0.70))\n",
      "-0.21 + 0.70(-1.69)\n",
      "-1.40\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.70, -0.70, -0.70]\n",
      "6: [0.00, 0.00, -7.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.800000\n",
      "Random Sample: 0.549397\n",
      "EXPLORATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: -0.70\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-0.70) + 0.70(-1.00 + 0.99(0.00))\n",
      "-0.21 + 0.70(-1.00)\n",
      "-0.91\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.91, -0.70, -0.70]\n",
      "6: [0.00, 0.00, -7.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.800000\n",
      "Random Sample: 0.876429\n",
      "EXPLOITATION\n",
      "Action Selected: Left\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: -0.70\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-1.00 + 0.99(-0.70))\n",
      "0.00 + 0.70(-1.69)\n",
      "-1.19\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.91, -0.70, -0.70]\n",
      "6: [-1.19, 0.00, -7.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.800000\n",
      "Random Sample: 0.588408\n",
      "EXPLORATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: -0.91\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-0.91) + 0.70(-1.00 + 0.99(0.00))\n",
      "-0.27 + 0.70(-1.00)\n",
      "-0.97\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.97, -0.70, -0.70]\n",
      "6: [-1.19, 0.00, -7.00, 0.00]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.800000\n",
      "Random Sample: 0.139339\n",
      "EXPLORATION\n",
      "Action Selected: Down\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-1.00 + 0.99(0.00))\n",
      "0.00 + 0.70(-1.00)\n",
      "-0.70\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.97, -0.70, -0.70]\n",
      "6: [-1.19, 0.00, -7.00, -0.70]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.800000\n",
      "Random Sample: 0.270969\n",
      "EXPLORATION\n",
      "Action Selected: Down\n",
      "Old Q-Value: -0.70\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-0.70) + 0.70(-1.00 + 0.99(0.00))\n",
      "-0.21 + 0.70(-1.00)\n",
      "-0.91\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.97, -0.70, -0.70]\n",
      "6: [-1.19, 0.00, -7.00, -0.91]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.800000\n",
      "Random Sample: 0.062571\n",
      "EXPLORATION\n",
      "Action Selected: Up\n",
      "Old Q-Value: -7.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-7.00) + 0.70(-10.00 + 0.99(0.00))\n",
      "-2.10 + 0.70(-10.00)\n",
      "-9.10\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |L| |\n",
      "| | |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.97, -0.70, -0.70]\n",
      "6: [-1.19, 0.00, -9.10, -0.91]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 3\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.700000\n",
      "Random Sample: 0.139396\n",
      "EXPLORATION\n",
      "Action Selected: Down\n",
      "Old Q-Value: -0.70\n",
      "Next Q-Value: -0.70\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-0.70) + 0.70(-1.00 + 0.99(-0.70))\n",
      "-0.21 + 0.70(-1.69)\n",
      "-1.40\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.97, -0.70, -1.40]\n",
      "6: [-1.19, 0.00, -9.10, -0.91]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.700000\n",
      "Random Sample: 0.880464\n",
      "EXPLOITATION\n",
      "Action Selected: Up\n",
      "Old Q-Value: -0.70\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-0.70) + 0.70(-1.00 + 0.99(0.00))\n",
      "-0.21 + 0.70(-1.00)\n",
      "-0.91\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "|L|B| |\n",
      "| | |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, 0.00]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.97, -0.91, -1.40]\n",
      "6: [-1.19, 0.00, -9.10, -0.91]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.700000\n",
      "Random Sample: 0.278971\n",
      "EXPLORATION\n",
      "Action Selected: Down\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: -0.91\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(-1.00 + 0.99(-0.91))\n",
      "0.00 + 0.70(-1.90)\n",
      "-1.33\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.97, -0.91, -1.40]\n",
      "6: [-1.19, 0.00, -9.10, -0.91]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.700000\n",
      "Random Sample: 0.065320\n",
      "EXPLORATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: -0.97\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-0.97) + 0.70(-1.00 + 0.99(0.00))\n",
      "-0.29 + 0.70(-1.00)\n",
      "-0.99\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.99, -0.91, -1.40]\n",
      "6: [-1.19, 0.00, -9.10, -0.91]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.700000\n",
      "Random Sample: 0.907207\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 0.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(0.00) + 0.70(10.00 + 0.99(0.00))\n",
      "0.00 + 0.70(10.00)\n",
      "7.00\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| | |L|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, -0.99, -0.91, -1.40]\n",
      "6: [-1.19, 7.00, -9.10, -0.91]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: 10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 4\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.600000\n",
      "Random Sample: 0.254186\n",
      "EXPLORATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: -0.99\n",
      "Next Q-Value: 7.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-0.99) + 0.70(-1.00 + 0.99(7.00))\n",
      "-0.30 + 0.70(5.93)\n",
      "3.85\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, 3.85, -0.91, -1.40]\n",
      "6: [-1.19, 7.00, -9.10, -0.91]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.600000\n",
      "Random Sample: 0.180567\n",
      "EXPLORATION\n",
      "Action Selected: Down\n",
      "Old Q-Value: -0.91\n",
      "Next Q-Value: 7.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-0.91) + 0.70(-1.00 + 0.99(7.00))\n",
      "-0.27 + 0.70(5.93)\n",
      "3.88\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, 3.85, -0.91, -1.40]\n",
      "6: [-1.19, 7.00, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.600000\n",
      "Random Sample: 0.147125\n",
      "EXPLORATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 7.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(7.00) + 0.70(10.00 + 0.99(0.00))\n",
      "2.10 + 0.70(10.00)\n",
      "9.10\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| | |L|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, 3.85, -0.91, -1.40]\n",
      "6: [-1.19, 9.10, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: 10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 5\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.500000\n",
      "Random Sample: 0.027699\n",
      "EXPLORATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 3.85\n",
      "Next Q-Value: 9.10\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(3.85) + 0.70(-1.00 + 0.99(9.10))\n",
      "1.16 + 0.70(8.01)\n",
      "6.76\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, 6.76, -0.91, -1.40]\n",
      "6: [-1.19, 9.10, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.500000\n",
      "Random Sample: 0.642473\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 9.10\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(9.10) + 0.70(10.00 + 0.99(0.00))\n",
      "2.73 + 0.70(10.00)\n",
      "9.73\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| | |L|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, 6.76, -0.91, -1.40]\n",
      "6: [-1.19, 9.73, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: 10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 6\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.400000\n",
      "Random Sample: 0.803688\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 6.76\n",
      "Next Q-Value: 9.73\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(6.76) + 0.70(-1.00 + 0.99(9.73))\n",
      "2.03 + 0.70(8.63)\n",
      "8.07\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, 8.07, -0.91, -1.40]\n",
      "6: [-1.19, 9.73, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.400000\n",
      "Random Sample: 0.649710\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 9.73\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(9.73) + 0.70(10.00 + 0.99(0.00))\n",
      "2.92 + 0.70(10.00)\n",
      "9.92\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| | |L|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, 8.07, -0.91, -1.40]\n",
      "6: [-1.19, 9.92, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: 10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 7\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.300000\n",
      "Random Sample: 0.135776\n",
      "EXPLORATION\n",
      "Action Selected: Down\n",
      "Old Q-Value: -1.40\n",
      "Next Q-Value: 8.07\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-1.40) + 0.70(-1.00 + 0.99(8.07))\n",
      "-0.42 + 0.70(6.99)\n",
      "4.48\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [-1.40, 8.07, -0.91, 4.48]\n",
      "6: [-1.19, 9.92, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.300000\n",
      "Random Sample: 0.097659\n",
      "EXPLORATION\n",
      "Action Selected: Left\n",
      "Old Q-Value: -1.40\n",
      "Next Q-Value: 8.07\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(-1.40) + 0.70(-1.00 + 0.99(8.07))\n",
      "-0.42 + 0.70(6.99)\n",
      "4.48\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.07, -0.91, 4.48]\n",
      "6: [-1.19, 9.92, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.300000\n",
      "Random Sample: 0.511931\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 8.07\n",
      "Next Q-Value: 9.92\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(8.07) + 0.70(-1.00 + 0.99(9.92))\n",
      "2.42 + 0.70(8.82)\n",
      "8.60\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.60, -0.91, 4.48]\n",
      "6: [-1.19, 9.92, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.300000\n",
      "Random Sample: 0.331171\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 9.92\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(9.92) + 0.70(10.00 + 0.99(0.00))\n",
      "2.98 + 0.70(10.00)\n",
      "9.98\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| | |L|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.60, -0.91, 4.48]\n",
      "6: [-1.19, 9.98, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: 10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 8\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.200000\n",
      "Random Sample: 0.644142\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 8.60\n",
      "Next Q-Value: 9.98\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(8.60) + 0.70(-1.00 + 0.99(9.98))\n",
      "2.58 + 0.70(8.88)\n",
      "8.79\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.79, -0.91, 4.48]\n",
      "6: [-1.19, 9.98, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.200000\n",
      "Random Sample: 0.722279\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 9.98\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(9.98) + 0.70(10.00 + 0.99(0.00))\n",
      "2.99 + 0.70(10.00)\n",
      "9.99\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| | |L|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.79, -0.91, 4.48]\n",
      "6: [-1.19, 9.99, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: 10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 9\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.100000\n",
      "Random Sample: 0.074595\n",
      "EXPLORATION\n",
      "Action Selected: Down\n",
      "Old Q-Value: 4.48\n",
      "Next Q-Value: 8.79\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(4.48) + 0.70(-1.00 + 0.99(8.79))\n",
      "1.34 + 0.70(7.70)\n",
      "6.74\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "|L| |W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.79, -0.91, 6.74]\n",
      "6: [-1.19, 9.99, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.100000\n",
      "Random Sample: 0.887789\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 8.79\n",
      "Next Q-Value: 9.99\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(8.79) + 0.70(-1.00 + 0.99(9.99))\n",
      "2.64 + 0.70(8.89)\n",
      "8.86\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.86, -0.91, 6.74]\n",
      "6: [-1.19, 9.99, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.100000\n",
      "Random Sample: 0.161384\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 9.99\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(9.99) + 0.70(10.00 + 0.99(0.00))\n",
      "3.00 + 0.70(10.00)\n",
      "10.00\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| | |L|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.86, -0.91, 6.74]\n",
      "6: [-1.19, 10.00, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: 10\n",
      "Done: True\n",
      "\n",
      "=============\n",
      "EPISODE 10\n",
      "==============\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.000000\n",
      "Random Sample: 0.167073\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 8.86\n",
      "Next Q-Value: 10.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(8.86) + 0.70(-1.00 + 0.99(10.00))\n",
      "2.66 + 0.70(8.90)\n",
      "8.89\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| |L|W|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.89, -0.91, 6.74]\n",
      "6: [-1.19, 10.00, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: -1\n",
      "Done: False\n",
      "\n",
      "---------------\n",
      "Epsilon Threshold: 0.000000\n",
      "Random Sample: 0.094360\n",
      "EXPLOITATION\n",
      "Action Selected: Right\n",
      "Old Q-Value: 10.00\n",
      "Next Q-Value: 0.00\n",
      "(1 - a)old_q + a(r + g(next_q)))\n",
      "(0.30)(10.00) + 0.70(10.00 + 0.99(0.00))\n",
      "3.00 + 0.70(10.00)\n",
      "10.00\n",
      "\n",
      "STATE:\n",
      "|C| | |\n",
      "| |B| |\n",
      "| | |L|\n",
      "\n",
      "Q Table:\n",
      "   [L, R, U, D]\n",
      "C: [0.00, 0.00, 0.00, 0.00]\n",
      "1: [0.00, 0.00, 0.00, 0.00]\n",
      "2: [0.00, 0.00, 0.00, 0.00]\n",
      "3: [-0.70, -7.00, 0.00, -1.33]\n",
      "B: [0.00, 0.00, 0.00, 0.00]\n",
      "4: [0.00, 0.00, 0.00, 0.00]\n",
      "5: [4.48, 8.89, -0.91, 6.74]\n",
      "6: [-1.19, 10.00, -9.10, 3.88]\n",
      "W: [0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "Reward: 10\n",
      "Done: True\n",
      "\n",
      "===========\n",
      "FINAL STATS\n",
      "Rewards: [-12, -11, -18, 6, 8, 9, 9, 7, 9, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class Env:\n",
    "    state = [2, 0]\n",
    "    rewards = [[1, -1, -1], [-1, -10, -1], [-1, -1, 10]]\n",
    "    q_values = []\n",
    "    epsilon = 1.0\n",
    "    episode = 0\n",
    "    learning_rate = 0.7\n",
    "    gamma = 0.99\n",
    "    \n",
    "    def __init__(self):\n",
    "        q_values = []\n",
    "        \n",
    "        for i in range(9):\n",
    "            row = []\n",
    "            for j in range(4):\n",
    "                row.append(0)\n",
    "            q_values.append(row)\n",
    "            \n",
    "        self.q_values = q_values\n",
    "        \n",
    "    def get_position(self, state):\n",
    "        return state[0] * 3 + state[1]\n",
    "        \n",
    "    def select_action(self):\n",
    "        action = None\n",
    "        sample = random.random()\n",
    "        epsilon_threshold = self.epsilon - (self.episode * 0.1)\n",
    "        \n",
    "        print('Epsilon Threshold: %f' % epsilon_threshold)\n",
    "        print('Random Sample: %f' % sample)\n",
    "        \n",
    "        if sample > epsilon_threshold:\n",
    "            print('EXPLOITATION')\n",
    "            position = self.get_position(self.state)\n",
    "            row = self.q_values[position]\n",
    "            action = row.index(max(row))\n",
    "        else:\n",
    "            print('EXPLORATION')\n",
    "            action = random.randrange(4)\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def step(self, action):\n",
    "        state = self.state.copy()\n",
    "        next_state = self.state\n",
    "        \n",
    "        # Calculate next state\n",
    "        if action == 0:\n",
    "            # Move left\n",
    "            next_state[1] -= 1\n",
    "        elif action == 1:\n",
    "            # Move right\n",
    "            next_state[1] += 1\n",
    "        elif action == 2:\n",
    "            # Move up\n",
    "            next_state[0] -= 1\n",
    "        elif action == 3:\n",
    "            # Move down\n",
    "            next_state[0] += 1\n",
    "        else:\n",
    "            raise ValueError('Invalid action')\n",
    "        \n",
    "        for i in range(2):\n",
    "            if next_state[i] < 0:\n",
    "                next_state[i] = 0\n",
    "            elif next_state[i] > 2:\n",
    "                next_state[i] = 2\n",
    "                \n",
    "        reward = self.rewards[next_state[0]][next_state[1]]\n",
    "        done = False\n",
    "        \n",
    "        position = self.get_position(state)\n",
    "        next_position = self.get_position(next_state)\n",
    "        \n",
    "        old_q = self.q_values[position][action]\n",
    "        next_q = max(self.q_values[next_position])\n",
    "        \n",
    "        a = self.learning_rate\n",
    "        \n",
    "        new_q = ((1 - a) * old_q) + (a * (reward + self.gamma * next_q))\n",
    "        self.q_values[position][action] = new_q\n",
    "        \n",
    "        print('Old Q-Value: %.2f' % old_q)\n",
    "        print('Next Q-Value: %.2f' % next_q)\n",
    "        print('(1 - a)old_q + a(r + g(next_q)))')\n",
    "        print('(%.2f)(%.2f) + %.2f(%.2f + %.2f(%.2f))' % (1 - a, old_q, a, reward, self.gamma, next_q))\n",
    "        print('%.2f + %.2f(%.2f)' % (((1-a) * old_q), a, (reward + self.gamma * next_q)))\n",
    "        print('%.2f' % new_q)\n",
    "        \n",
    "        if next_state == [1, 1] or next_state == [2, 2]:\n",
    "            done = True\n",
    "        \n",
    "        self.print_state()\n",
    "        self.print_q_table()\n",
    "        \n",
    "        return state, reward, done\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = [2, 0]\n",
    "        self.episode += 1\n",
    "    \n",
    "    def print_state(self):        \n",
    "        rows = [\n",
    "            '|C| | |',\n",
    "            '| |B| |',\n",
    "            '| | |W|'\n",
    "        ]\n",
    "\n",
    "        row = list(rows[self.state[0]])\n",
    "        row[self.state[1] * 2 + 1] = 'L'\n",
    "        rows[self.state[0]] = ''.join(row)\n",
    "        \n",
    "        print('\\nSTATE:')\n",
    "        print(rows[0])\n",
    "        print(rows[1])\n",
    "        print(rows[2])\n",
    "        \n",
    "    def print_q_table(self):\n",
    "        positions = ['C', 1, 2, 3, 'B', 4, 5, 6, 'W']\n",
    "        \n",
    "        print('\\nQ Table:\\n   [L, R, U, D]')\n",
    "\n",
    "        for position, row in zip(positions, self.q_values):\n",
    "            print('%s: [%.2f, %.2f, %.2f, %.2f]' % (position, row[0], row[1], row[2], row[3]))\n",
    "        \n",
    "    \n",
    "action_name = ['Left', 'Right', 'Up', 'Down']\n",
    "env = Env()\n",
    "env.print_state()\n",
    "done = False\n",
    "max_episodes = 11\n",
    "\n",
    "rewards = []\n",
    "\n",
    "for i in range(max_episodes):\n",
    "    print('\\n=============')\n",
    "    print('EPISODE %d' % i)\n",
    "    print('==============')\n",
    "    \n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        print('\\n---------------')\n",
    "        action = env.select_action()\n",
    "        print('Action Selected: %s' % action_name[action])\n",
    "        _, reward, done = env.step(action)\n",
    "        total_reward += reward\n",
    "        print('\\nReward: %d' % reward)\n",
    "        print('Done: %s' % done)\n",
    "\n",
    "    rewards.append(total_reward)\n",
    "    env.reset()\n",
    "    done = False\n",
    "    \n",
    "print('\\n===========')\n",
    "print('FINAL STATS')\n",
    "print('Rewards: %s' % rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
